{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3a0435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sample: ['Sunny', 'Cool'] -> Predicted Class: Yes\n",
      "Test Sample: ['Overcast', 'Mild'] -> Predicted Class: Yes\n",
      "Test Sample: ['Rain', 'Hot'] -> Predicted Class: No\n",
      "Test Sample: ['Sunny', 'Hot'] -> Predicted Class: No\n",
      "\n",
      "--- Model Learned Parameters ---\n",
      "Label Counts: {'No': 5, 'Yes': 9}\n",
      "Feature Counts: {'No': {'Outlook': {'Sunny': 3, 'Rain': 2}, 'Temp': {'Hot': 2, 'Cool': 1, 'Mild': 2}}, 'Yes': {'Outlook': {'Overcast': 4, 'Rain': 3, 'Sunny': 2}, 'Temp': {'Hot': 2, 'Mild': 4, 'Cool': 3}}}\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "dataset = [\n",
    "    ['Sunny', 'Hot', 'No'],\n",
    "    ['Sunny', 'Hot', 'No'],\n",
    "    ['Overcast', 'Hot', 'Yes'],\n",
    "    ['Rain', 'Mild', 'Yes'],\n",
    "    ['Rain', 'Cool', 'Yes'],\n",
    "    ['Rain', 'Cool', 'No'],\n",
    "    ['Overcast', 'Cool', 'Yes'],\n",
    "    ['Sunny', 'Mild', 'No'],\n",
    "    ['Sunny', 'Cool', 'Yes'],\n",
    "    ['Rain', 'Mild', 'Yes'],\n",
    "    ['Sunny', 'Mild', 'Yes'],\n",
    "    ['Overcast', 'Mild', 'Yes'],\n",
    "    ['Overcast', 'Hot', 'Yes'],\n",
    "    ['Rain', 'Mild', 'No']\n",
    "]\n",
    "\n",
    "features = [\"Outlook\", \"Temp\"]  # Feature names\n",
    "\n",
    "def train_naive_bayes(data):\n",
    "    label_counts = {}      \n",
    "    feature_counts = {}   \n",
    "\n",
    "    for row in data:\n",
    "        outlook, temp, label = row\n",
    "\n",
    "        # Count each label\n",
    "        label_counts[label] = label_counts.get(label, 0) + 1\n",
    "\n",
    "        # Initialize dictionary if new label\n",
    "        if label not in feature_counts:\n",
    "            feature_counts[label] = {\"Outlook\": {}, \"Temp\": {}}\n",
    "\n",
    "        # Count Outlook feature\n",
    "        feature_counts[label][\"Outlook\"][outlook] = feature_counts[label][\"Outlook\"].get(outlook, 0) + 1\n",
    "\n",
    "        # Count Temp feature\n",
    "        feature_counts[label][\"Temp\"][temp] = feature_counts[label][\"Temp\"].get(temp, 0) + 1\n",
    "\n",
    "    return label_counts, feature_counts\n",
    "\n",
    "\n",
    "# Prediction function\n",
    "\n",
    "def predict_naive_bayes(x, label_counts, feature_counts):\n",
    "    \"\"\"\n",
    "    x = list of feature values [Outlook, Temp]\n",
    "    \"\"\"\n",
    "    total_samples = sum(label_counts.values())\n",
    "    probs = {}\n",
    "\n",
    "    for label in label_counts:\n",
    "        # Start with prior probability: log(P(label))\n",
    "        probs[label] = math.log(label_counts[label] / total_samples)\n",
    "\n",
    "        # Calculate conditional probabilities for each feature\n",
    "        for i, feature in enumerate(features):\n",
    "            value = x[i]\n",
    "            # Count how many times feature=value given label\n",
    "            count = feature_counts[label][feature].get(value, 0)\n",
    "\n",
    "            # Total count of current feature for this label\n",
    "            total_feature_count = label_counts[label]\n",
    "\n",
    "            # Number of unique values in this feature\n",
    "            unique_feature_values = len(feature_counts[label][feature])\n",
    "\n",
    "            # Apply Laplace Smoothing\n",
    "            likelihood = (count + 1) / (total_feature_count + unique_feature_values)\n",
    "\n",
    "            # Use log to prevent underflow\n",
    "            probs[label] += math.log(likelihood)\n",
    "\n",
    "    # Return label with highest probability\n",
    "    return max(probs, key=probs.get)\n",
    "\n",
    "# Train the model\n",
    "label_counts, feature_counts = train_naive_bayes(dataset)\n",
    "\n",
    "\n",
    "test_samples = [\n",
    "    ['Sunny', 'Cool'],\n",
    "    ['Overcast', 'Mild'],\n",
    "    ['Rain', 'Hot'],\n",
    "    ['Sunny', 'Hot']\n",
    "]\n",
    "\n",
    "for sample in test_samples:\n",
    "    prediction = predict_naive_bayes(sample, label_counts, feature_counts)\n",
    "    print(f\"Test Sample: {sample} -> Predicted Class: {prediction}\")\n",
    "\n",
    "print(\"\\n--- Model Learned Parameters ---\")\n",
    "print(\"Label Counts:\", label_counts)\n",
    "print(\"Feature Counts:\", feature_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2305c66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
